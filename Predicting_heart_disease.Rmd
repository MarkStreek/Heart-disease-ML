---
title: "Predicting Heart Disease"
author: "Mark van de Streek"
date: "`r Sys.Date()`"
output:
  pdf_document:
    number_sections: yes
  word_document: default
  html_document:
    df_print: paged
editor_options:
  markdown:
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
```

# Practical assignment bioinformatics - predicting heart diseases

```{r}
# Copyright (c) 2023 <Mark van de Streek>. 
# Licensed under GPLv3. See gpl.md
```

Loading all the packages that are necessary for this research.

```{r, echo=TRUE, error=FALSE, message=FALSE, warning=FALSE}
# Loading the packages
library(pander)
library(ggplot2)
library(GGally)
library(ggcorrplot)
library(gridExtra)
library(dplyr)
library(data.table)
library(tidyverse)
```

\newpage

# Introduction

This study examines a dataset \cite{dataset} on predicting heart disease
based on clinical variables.

The ultimate goal of this research is to create a machine learning model
that predicts whether a patient has heart disease.

The dataset contains data from people with and without a heart disease.
The last column shows whether the patient has heart disease (presence)
or not (absence). The logbook often refers to the classification column.
It is then referred to as "presence" and "absence" of heart disease.

research question of the research: Which medical properties are
important to be so accurate possible to predict a heart
condition/abnormality?

## Details of the data

The dataset contains data from 270 patients. There are 13 independent
predictive variables for each patient. These variables are described in
further detail in the codebook.

The dataset comes from the UCI repository. The Machine Learning
Repository (UCI Repository) is a collection of databases and domains
used by the machine learning community to create machine learning
algorithms.

The dataset was created and merged by the following 4 agencies:

1.  Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.
2.  University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.
3.  University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.
4.  V.A. Medical Center, Long Beach and Cleveland Clinic Foundation:
    Robert Detrano, M.D., Ph.D.

The data was all collected in medical institutions. Good to remember
that there can be a difference between medical equipment. However, these
are of course not cheap devices that are found in the living room at
home, for example. So the deviation will not be very large

## What is heart disease?

What is a heart disease and how many people have one. Why is this
research important?

\newpage

# Exploration of the data

In the very first part of this logbook, the data will be examined
exploratively. I.e., for example, the distribution of values,
correlations, characteristics, etc. is looked at. This is all explained
below.

## Data structure and Codebook

### Reading the data

Loading the data from the .csv file.

```{r}
data <- read.csv("Heart_Disease_Prediction.csv", header = T, sep = ",")
data <- data.frame(data)
```

An overview of the data will be stored inside a codebook, so it's easy
to change/translate. After that's done, it's easier to show all the
columns' datatypes and description.

```{r}
codebook <- data.frame(
  attributes = c("index", "Age", "Sex", "Chest.pain.type", 
                 "BP", "Cholesterol", "FBS.over.120", 
                 "EKG.results","Max.HR", "Exercise.angina", 
                 "ST.depression", "Slope.of.ST", "Number.of.vessels.fluro", 
                 "Thallium", "Heart.Disease"),
  unit = c("-", "years", "-", "-", "mm/Hg", "mg/dl","-", "-", "Beats/minute", 
           "-", "-", "-", "-", "-", "-"),
  dtype = c("int","int","factor","factor","int","int","factor","factor",
            "int","factor","int","factor","factor","factor","factor"),
  description = c("Patient number", "The age of the patient", 
                  "The gender of the patient", 
                  "The type of chest pain experienced by the patient", 
                  "The blood pressure level of the patient", 
                  "The cholesterol level of the patient", 
                  "The fasting blood sugar test results over 120 mg/dl", 
                  "The electrocardiogram results of the patient", 
                  "The maximum heart rate levels achieved during exercise testing", 
                  "The angina experienced during exercise testing", 
                  "The ST depression on a Electrocardiogram", 
                  "The slope of ST segment electrocardiogram readings", 
                  "The amount vessels seen in Fluoroscopy images", 
                  "Thallium Stress test findings", 
                  "Whether or not the patient has been diagnosed with Heart Disease"))
```

\newpage

### Description of the attributes

With the codebook we can print a overview of all the variables.

```{r}
# Print an overview of the columns with right datatypes and description
pander(codebook)
```

As shown above, the dataset contains some 'factor' attributes. These
columns need some extra declaration to understand.

Additional description of nomial attriutes in the dataset:

1.  sex
    -   1 = Male

    -   0 = Female
2.  Chest pain type
    -   Value 1: Typical angina

    -   Value 2: Atypical angina

    -   Value 3: Non-anginal pain (pain without disease)

    -   Value 4: Asymptomatic
3.  EKG results
    -   Value 0: Normal

    -   Value 1: ST-T wave abnormality

    -   Value 2: Probable or definite LVH (thickening of the walls of
        the left ventricle, main chamber)
4.  FBS over 120 (Blood glucose level measured after fasting for at
    least 8 hours)
    -   Value 1: True

    -   Value 0: False
5.  Slope of ST Depression (Segment in EKG that may indicates a disease)
    -   Value 1: Up sloping

    -   Value 2: Flat

    -   Value 3: Down sloping
6.  Exercise induced angina (Narrowed blood vessels that deliver
    oxygen/nutrients to heart)
    -   Value 1 = Yes

    -   Value 0 = No
7.  Number of major vessels coloured by fluoroscopy
    -   range from 1 to 3
8.  Thallium (how much blood is reaching different parts of your heart)
    -   Value 3: Normal

    -   Value 6: Fixed defect

    -   Value 7: Reversible defect

\newpage

With all the right datatypes given, it is possible to change all the
columns to the right one. R does a good job by automatically choosing
the right datatype for the int/dbl columns. For that reason, you only
have to change the nominal datatypes. This is done below.

```{r}
for (i in 1:ncol(data)) {
  if (codebook[,3][i] == "factor") {
    data[, codebook[,1][i]] <- sapply(data[, codebook[,1][i]], as.factor)
  }
}
```

Now the data is all in the right datatypes, we can look at the
dimensions of the data.

```{r}
dims <- dim(data)
sprintf("Amount of rows: %.f, amount of columns: %.f", dims[1], dims[2])
```

The data contains 270 rows. That means there is data from 270 patients.
This corresponds to expectations. For all these patients there are 14
values that say something about that pearson. Not 15 because the first
column is the index.

### Missing values

As the name says, this section will look at the missing values in the
dataset. Missing values can have major influence on the model. To make
sure there aren't a lot of missing values in the dataset, we will check
this with a simple loop.

```{r}
cat("Missing values:", any(is.na(data)))
```

As you can see above, there are no missing values in the dataset. beyond
that, there is little to say about it.

\newpage

## Univariate analysis

This section examines each variable in the dataset separately. The
distribution of numerical values, outliers of numerical values and
variation of ordinal values will be examined

### Variation of the data

There are a lot of numeric columns in the dataset. This means that the
distribution shows us a good first impression of the data.

We will look at the nominal/ordinal values as well, so we're going to
filter these first.

```{r}
numeric.columns <- c(2,5,6,9,11)
nominal.columns <- c(3,4,7,8,10,12,13,14,15)
```

#### Variation of numeric attributes

We made sure there aren't missing values in the dataset. Let's look at
the range of columns.

```{r}
pander(summary(data[numeric.columns]))
```

Looking at the ST.depression, thit column has a wide range between
minimum and maximum. The median and mean value is also far from the
maximum. These could be outlier values, but it could also just be how
the value is constructed.

\newpage

Now let's look at the distribution. This may give us a slightly clearer
picture

```{r}
c1 <- ggplot(data, aes(x=Age)) + geom_histogram(bins = 15) + 
  labs(title = "Distribution Age Attribute") + xlab("Age (in years)") + 
  theme(axis.title.x = element_text(colour = "red", size = 8))

c2 <- ggplot(data, aes(x=BP)) + geom_histogram(bins = 10) + 
  labs(title = "Distribution Blood pressure Attribute") + 
  xlab("Blood pressure (in mm/HG)") + theme(axis.title.x = 
                                  element_text(colour = "red", size = 8))

c3 <- ggplot(data, aes(x = Cholesterol)) + geom_histogram(bins = 40) + 
  labs(title = "Distribution Cholesterol Attribute") + 
  xlab("Cholesterol in mg/dl") + 
  theme(axis.title.x = element_text(colour = "red", size = 8))

c4 <- ggplot(data, aes(x=Max.HR)) + geom_histogram(bins = 30) + 
  labs(title = "Distribution Max. heart rate Attribute") + 
  xlab("Heart beats (per minute)") + theme(axis.title.x = 
                                    element_text(colour = "red", size = 8))

c5 <- ggplot(data, aes(x=ST.depression)) + geom_histogram(bins = 30) + 
  labs(title = "Distribution ST depression Attribute") + 
  xlab("ST depression (in relative with the state of rest)") +
  theme(axis.title.x = element_text(colour = "red", size = 8))

grid.arrange(c1,c2,c3,c4,c5, ncol = 2)
```

The above graphs tells us that Cholesterol is quite well normal
distributed. The same can be said for BP. Max.HR and Age appears to be
split more towards the right. ST.depression shows a very high peak at
the first bin.

Let's transform the data with log10 and see if the distribution is
better/more observable.

```{r}
c1 <- ggplot(data, aes(x=log10(Age))) + geom_histogram(bins = 15) + 
  labs(title = "Distribution Age Attribute") + xlab("Age (in years)") + 
  theme(axis.title.x = element_text(colour = "red", size = 8))

c2 <- ggplot(data, aes(x=log10(BP))) + geom_histogram(bins = 10) + 
  labs(title = "Distribution Blood pressure Attribute") + 
  xlab("Blood pressure (in mm/HG)") + theme(axis.title.x = 
                                  element_text(colour = "red", size = 8))

c3 <- ggplot(data, aes(x = log10(Cholesterol))) + geom_histogram(bins = 40) + 
  labs(title = "Distribution Cholesterol Attribute") + 
  xlab("log10 of Cholesterol in mg/dl") + 
  theme(axis.title.x = element_text(colour = "red", size = 8))

c4 <- ggplot(data, aes(x=log10(Max.HR))) + geom_histogram(bins = 30) + 
  labs(title = "Distribution Max. heart rate Attribute") + 
  xlab("Heart beats (per minute)") + theme(axis.title.x = 
                                    element_text(colour = "red", size = 8))

c5 <- ggplot(data, aes(x=log10(ST.depression))) + geom_histogram(bins = 30) + 
  labs(title = "Distribution ST depression Attribute") + 
  xlab("ST depression (in relative with the state of rest)") +
  theme(axis.title.x = element_text(colour = "red", size = 8))

grid.arrange(c1,c2,c3,c4,c5, ncol = 2)
```

The cholesteral attribute is good normal distributed now. ST.depression
is not good normal distributed but is more readable. However, in
ST.depression there is a high peak at - infinity. The attribute is still
not normally distributed, so it is left behind for the transformation.

```{r}
data$Cholesterol <- log10(data$Cholesterol)
```

\newpage

With the distributions displayed, we can then begin to identify
*possible* outliers. For this we use a violin plot. That's because a
violin plot allows you to examine the distribution of the data and spot
some outliers. It can also be immediately seen whether the outliers have
a strong influence on the distribution.

```{r}
numeric.frame <- data.frame(
  Age = rep("Age", length(data$Age)),
  BP = rep("BP", length(data$BP)),
  Max.HR = rep("Max.HR", length(data$Max.HR)),
  Cholesterol = rep("Cholesterol", length(data$Cholesterol)),
  Age.value = data$Age,
  BP.value = data$BP,
  Max.HR.value = data$Max.HR,
  Cholesterol.value = data$Cholesterol)

p1 <- ggplot(numeric.frame, aes(x=Age, y=Age.value, colour = Age)) + 
  theme(legend.position = "top") + coord_flip() + 
  geom_violin(trim = F, alpha = 1, color = "#FF5733") + geom_jitter(alpha = 0.35, color = "#FF5733") +
  ylab("Age (in years)") + xlab("Attribute")

p2 <- ggplot(numeric.frame, aes(x=BP, y=BP.value)) + 
  theme(legend.position = "top") + coord_flip() +
  geom_violin(trim = F, alpha = 1, color = "#A7FF33") + geom_jitter(alpha = 0.35, color = "#A7FF33") +
  ylab("BP (in mm/Hg)") + xlab("Attribute")

p3 <- ggplot(numeric.frame, aes(x=Max.HR, y=Max.HR.value)) + 
  theme(legend.position = "top") + coord_flip() +
  geom_violin(trim = F, alpha = 1, color = "#33E6FF") + geom_jitter(alpha = 0.35, color = "#33E6FF") +
  ylab("Max.HR (in beats/minute)") + xlab("Attribute")

p4 <- ggplot(numeric.frame, aes(x=Cholesterol, y=Cholesterol.value)) + 
  theme(legend.position = "top") + coord_flip() +
  geom_violin(trim = F, alpha = 1, color = "#DC67B2") + geom_jitter(alpha = 0.35, color = "#DC67B2") +
  ylab("Cholesterol (in mg/dl)") + xlab("Attribute")

grid.arrange(p1,p2,p3,p4, ncol = 2)
```

The data contains few outliers. BP and Max.HR has a number of points
that differ slightly. But looking at the distribution, it still looks
quite well normal. We can conclude that:

-   There are no major deviations in the distribution of the data
-   The numerical data contain no notable outliers

\newpage

#### Variation of nominal/ordinal attributes

Let's look at the nominal values new. We are going to plot how often
these occur. This is to be able to see whether all classes are
represented.

```{r}
p1 <- ggplot(data, aes(x = Sex, fill = Sex)) + geom_bar()
p2 <- ggplot(data, aes(x = Chest.pain.type, fill = Chest.pain.type)) + geom_bar()
p3 <- ggplot(data, aes(x = FBS.over.120, fill = FBS.over.120)) + geom_bar()
p4 <- ggplot(data, aes(x = EKG.results, fill = EKG.results)) + geom_bar()
p5 <- ggplot(data, aes(x = Exercise.angina, fill = Exercise.angina)) + geom_bar()
p6 <- ggplot(data, aes(x = Slope.of.ST, fill = Slope.of.ST)) + geom_bar()
p7 <- ggplot(data, aes(x = Number.of.vessels.fluro)) + geom_bar()
p8 <- ggplot(data, aes(x = Thallium, fill = Thallium)) + geom_bar()
p9 <- ggplot(data, aes(x = Heart.Disease, fill = Heart.Disease)) + geom_bar()

grid.arrange(p1,p2,p3,p4,p5,p6,p7,p8,p9, ncol = 3, 
             top = "Barplots of all the nominal/ordinal valus")
```

The dataset contains more man than women. Most values lean towards
'healthy' people. There are also more people who do not have a condition
than do. So this difference partly comes from here. However, there are
also many people who do have a condition, but have few or no complaints,
for example, see figure Chest.pain.type.

conclusions:

-   Comparatively few people have an FBS of over 120
-   There seems to be enough distribution in these attributes to train a
    good model (this says nothing about the usability of all attributes)

\newpage

### Class distribution

For our model it's important to know how the classes are distributed. We
can have a big dataset, but if it's only "absence" people, we can't say
much about it.

```{r}
df <- data.frame(
  group = c("Presence", "Absence"),
  value = c(sum(data[15] == "Presence"), sum(data[15] == "Absence"))
)

ggplot(df, aes(x = "", y = value, fill = group)) +
  geom_col(color = "black") +
  geom_text(aes(label = value),
            position = position_stack(vjust = 0.5)) +
  coord_polar(theta = "y") + labs(title = "Pie chart of class distribution", 
  subtitle = "The number of people per group") + theme_void() + 
  theme(legend.position = "bottom", plot.title = element_text(face = "bold", 
      size = 18, hjust = 0.5), plot.subtitle = element_text(hjust = 0.5)) 
```

As you can see, the classes are not exactly evenly represented. But it
certainly has no major deviation.

\newpage

## Bivariate analysis

In this sector, not one, but several variables are considered. By this
we mean that we will look at each other. For example, how much
correlation certain attributes have. First, we will compare age between
groups

### Comparing the numeric attributes with classification attribute

Let's take a closer look at the patients and numeric values. Perhaps we
spot some initial differences.

```{r}
age.frame <- data.frame(
  Patient = c(rep("Presence", 120), rep("Absence", 150)),
  Age = c(data$Age[data$Heart.Disease == "Presence"], 
             data$Age[data$Heart.Disease == "Absence"]),
  BP = c(data$BP[data$Heart.Disease == "Presence"], 
         data$BP[data$Heart.Disease == "Absence"]),
  Cholesterol = c(data$Cholesterol[data$Heart.Disease == "Presence"], 
                  data$Cholesterol[data$Heart.Disease == "Absence"]),
  Max.HR = c(data$Max.HR[data$Heart.Disease == "Presence"], 
             data$Max.HR[data$Heart.Disease == "Absence"]),
  ST.depression = c(data$ST.depression[data$Heart.Disease == "Presence"], 
                    data$ST.depression[data$Heart.Disease == "Absence"]))

b1 <- ggplot(age.frame, aes(x = Patient, y = Age, fill=Patient)) + 
  geom_boxplot() + labs(title = "Boxplot from patients age", 
                        subtitle = "Ages between presence and Absence") + 
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 10), 
        plot.subtitle = element_text(hjust = 0.5, size = 7)) + ylab("Age (in years)")

b2 <- ggplot(age.frame, aes(x = Patient, y = BP, fill=Patient)) + 
  geom_boxplot() + labs(title = "Boxplot from patients BP", 
                        subtitle = "BP between presence and Absence") + 
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 10), 
        plot.subtitle = element_text(hjust = 0.5, size = 7)) + ylab("BP (in mm/Hg)")

b3 <- ggplot(age.frame, aes(x = Patient, y = Cholesterol, fill=Patient)) + 
  geom_boxplot() + labs(title = "Boxplot from patients Cholesterol", 
                        subtitle = "Cholesterol between presence and Absence") + 
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 10), 
        plot.subtitle = element_text(hjust = 0.5, size = 7)) + ylab("Cholesterol (in mg/dl)")

b4 <- ggplot(age.frame, aes(x = Patient, y = Max.HR, fill=Patient)) + 
  geom_boxplot() + labs(title = "Boxplot from patients Max.HR", 
                        subtitle = "Max.HR between presence and Absence") + 
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 10), 
        plot.subtitle = element_text(hjust = 0.5, size = 7)) + 
  ylab("Heart rate (in beats/minute)")

b5 <- ggplot(age.frame, aes(x = Patient, y = ST.depression, fill=Patient)) + 
  geom_boxplot() + labs(title = "Boxplot from patients ST.depression", 
                        subtitle = "ST.depression between presence and Absence") + 
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 10), 
        plot.subtitle = element_text(hjust = 0.5, size = 7)) + ylab("ST.depression value")

grid.arrange(b1,b2,b3,b4,b5, ncol = 2)
```

The results show that the age is slightly higher in the presence group.
It can be concluded that patients with a presence-condition are often
slightly older. The Max.HR is also higher in the absence group. And
ST.depression is higher in the Presence group.

\newpage

We can confirm the differneces with statistical tests.

```{r}
age.test <- t.test(data$Age[data$Heart.Disease == "Presence"], 
       data$Age[data$Heart.Disease == "Absence"])$p.value
bp.test <- t.test(data$BP[data$Heart.Disease == "Presence"], 
                  data$BP[data$Heart.Disease == "Absence"])$p.value
cholesterol.test <- t.test(data$Cholesterol[data$Heart.Disease == "Presence"], 
                           data$Cholesterol[data$Heart.Disease == "Absence"])$p.value
max.hr.test <- t.test(data$Max.HR[data$Heart.Disease == "Presence"], 
                      data$Max.HR[data$Heart.Disease == "Absence"])$p.value
st.depression.test <- t.test(data$ST.depression[data$Heart.Disease == "Presence"], 
                             data$ST.depression[data$Heart.Disease == "Absence"])$p.value

t.test.results <- data.frame(
  Attributes = c("Age", "BP", "Cholesterol", "Max.HR", "ST depression"),
  P.Value = c(age.test, bp.test, cholesterol.test, 
               max.hr.test, st.depression.test))

pander(t.test.results)
```

The cholesterol p-value is less than 0.05, but the value is just below
0.05. The difference could therefore be characterized as small. The rest
of the values have a significant difference between both groups

\newpage

### Comparing the Categorial attributes with classification attribute

Now let's do the same as above, but then for categorial data.

```{r}
b1 <- ggplot(data, aes(x = Sex, fill=Heart.Disease)) + 
  geom_bar() + labs(title = "Boxplot from patients Sex", 
                        subtitle = "Sex between presence and Absence") + 
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 8.5), 
        plot.subtitle = element_text(hjust = 0.5, size = 7)) + ylab("Amount")

b2 <- ggplot(data, aes(x = Chest.pain.type, fill=Heart.Disease)) + 
  geom_bar() + labs(title = "Boxplot from patients Chest.pain.type", 
                    subtitle = "Chest.pain.type between presence and Absence") + 
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 8.5), 
        plot.subtitle = element_text(hjust = 0.5, size = 7)) + ylab("Amount")

b3 <- ggplot(data, aes(x = FBS.over.120, fill=Heart.Disease)) + 
  geom_bar() + labs(title = "Boxplot from patients FBS.over.120", 
                      subtitle = "FBS.over.120 between presence and Absence") + 
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 8.5), 
        plot.subtitle = element_text(hjust = 0.5, size = 7)) + ylab("Amount")

b4 <- ggplot(data, aes(x = EKG.results, fill=Heart.Disease)) + 
  geom_bar() + labs(title = "Boxplot from patients EKG.results", 
                        subtitle = "EKG.results between presence and Absence") + 
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 8.5), 
        plot.subtitle = element_text(hjust = 0.5, size = 7)) + ylab("Amount")

b5 <- ggplot(data, aes(x = Exercise.angina, fill=Heart.Disease)) + 
  geom_bar() + labs(title = "Boxplot from patients Exercise.angina", 
                  subtitle = "Exercise.angina between presence and Absence") + 
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 8.5), 
        plot.subtitle = element_text(hjust = 0.5, size = 7)) + ylab("Amount")

b6 <- ggplot(data, aes(x = Slope.of.ST, fill=Heart.Disease)) + 
  geom_bar() + labs(title = "Boxplot from patients Slope.of.ST", 
                        subtitle = "Slope.of.ST between presence and Absence") + 
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 8.5), 
        plot.subtitle = element_text(hjust = 0.5, size = 7)) + ylab("Amount")

b7 <- ggplot(data, aes(x = Number.of.vessels.fluro, fill=Heart.Disease)) + 
  geom_bar() + labs(title = "Boxplot from patients Number.of.vessels.fluro", 
          subtitle = "Number.of.vessels.fluro between presence and Absence") + 
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 8.5), 
        plot.subtitle = element_text(hjust = 0.5, size = 7)) + ylab("Amount")

b8 <- ggplot(data, aes(x = Thallium, fill=Heart.Disease)) + 
  geom_bar() + labs(title = "Boxplot from patients Thallium", 
                        subtitle = "Thallium between presence and Absence") + 
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 8.5), 
        plot.subtitle = element_text(hjust = 0.5, size = 7)) + ylab("Amount")

grid.arrange(b1, b2, b3, b4, ncol = 2)
grid.arrange(b5, b6, b7, b8, ncol = 2)
```

There are many more men than women with a heart disease. Most people
with a condition experience no pain on the chest. The ratio between sick
and not sick between FBS over 120 is the same. There are many more
people without FBS over 120. There are few people with exercise angina
and no condition. Thallium 7 is most common in people with a condition.

\newpage

Let's do statistical tests for this as well.

```{r}
sex.test <- chisq.test(data$Sex, data$Heart.Disease, correct = FALSE)$p.value
chest.pain.type.test <- chisq.test(data$Chest.pain.type, data$Heart.Disease, correct = FALSE)$p.value
FBS.test <- chisq.test(data$FBS.over.120, data$Heart.Disease, correct = FALSE)$p.value 
EKG.test <- chisq.test(data$EKG.results, data$Heart.Disease, correct = FALSE)$p.value
Exercise.test <- chisq.test(data$Exercise.angina, data$Heart.Disease, correct = FALSE)$p.value
Slope.test <- chisq.test(data$Slope.of.ST, data$Heart.Disease, correct = FALSE)$p.value
Number.test <- chisq.test(data$Number.of.vessels.fluro, data$Heart.Disease, correct = FALSE)$p.value
Thallium.test <- chisq.test(data$Thallium, data$Heart.Disease, correct = FALSE)$p.value

chisq.results <- data.frame(
  Attributes = c(
    "Sex", "Chest Pain Type", "FBS over 120", "EKG results",
    "Exercise angina", "Slope of ST", "Number of vessels", "Thallium"),
  P.Value = c(sex.test, chest.pain.type.test, FBS.test, EKG.test, 
            Exercise.test, Slope.test, Number.test, Thallium.test))

pander(chisq.results)
```

All p-values except FBS over 120 have a p-value lower than 0.05. This
means that all these values are related to the classification column
(Presence/Absence). The lowest p-values are of course the most
correlated.

\newpage

### Corrolation between attributes

As mentioned earlier, the main goal of this research was to develop a
machine learning model. For this model, it is useful to see which
attributes may be important. We will compare all numeric attributes with
each other. The goal is to demonstrate similarities or differences.

Scatterplots are plotted between all attributes. This makes it possible
to see how far apart the groups presence/absence are. Or just how close
they are to each other.

```{r}
ggpairs( data[numeric.columns], ggplot2::aes(colour=data$Heart.Disease), 
         progress = F, upper = "blank", legend = 1) + 
  labs(title = "Pairplot of the numeric attributes") + 
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 20), axis.text.y = element_blank(), legend.position = "bottom")
```

The figure above shows a number of things. It shows the similarities
between all variables. However, it is of course much clearer to simply
attach a number to the similarities. This happens below with a
correlation heat map.

Conclusions pairplot:

-   There is a small similaritie in the age attribute
-   The maximum heart rate appears to be lower in people who have a
    condition

\newpage

```{r}
colMA <- function(n = 3) {
  colorRampPalette(c("red", "grey", "lightblue"), space = "rgb")(n)
}


# plotting corr heatmap
ggcorrplot(cor(data[numeric.columns]), colors = colMA(), 
           lab = T, lab_col = "white", lab_size = 3) +
  labs(title = "Correlation Heatmap of the numeric attributes") + 
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 20)) 
```

The output tells us that there are some values that are slightly to
moderately correlated. Blood pressure and age have the highest
correlation. Furthermore, there are no values that stand out. ST
depression and maximum heart rate have the least correlation

Conclusion:

-   BP and Age have the highest correlation
-   There are no very high or low correlations, the values complement
    each other well

\newpage

## Conclusions of the tests sorted

Below is a table in which all p-values are sorted.

```{r}
combined <- bind_rows(chisq.results, t.test.results)
pander(combined[order(combined$P.Value),])
```

The attribute thallium is most related to disease. This value is going
to be important for the model. The list if followed by chest pain type.
The FBS value over 120 will be the least useful

\newpage

# Clean Dataset

As told earlier, some columns have been log10 transformed. We are now
going to make a 'clean' dataset. I.e., a dataset with usable columns and
with the right range.

Let's delete the index column. This column is unnecessary and we don't
need it for our machine learning model later on.

```{r}
data <- data[ -c(1) ]
```

For the clean dataset it is also easy to read a number of values more
quickly. Numbers cannot be read quickly, so we will convert (simple)
values into words.

```{r}
levels(data$Sex) <- c("Male", "Female")
levels(data$FBS.over.120) <- c(FALSE, TRUE)
levels(data$Exercise.angina) <- c("No", "Yes")
levels(data$Chest.pain.type) <- c("Asymptomatic", "Non-anginal pain (pain without disease)", 
                                  "Atypical angina", "Typical angina")
levels(data$EKG.results) <- c("Probable or definite LVH", "Normal", "ST-T wave abnormality")
levels(data$Slope.of.ST) <- c("Flat", "Up sloping", "Down sloping")
levels(data$Number.of.vessels.fluro) <- c("3", "0", "1", "2")
levels(data$Thallium) <- c("Normal", "Reversible defect", "Fixed defect")
```

We are now creating three other datasets to test algorithms in weka.
First, a dataset is created that contains only the attributes of the top
5 lowest p-values. Then another data set is saved in which the remaining
numeric columns are transformed. Finally, a dataset will be created,
containing only the simple attributes. These attributes can easily be
taken with a simple test.

```{r}
data.top5 <- data[c("Thallium", "Chest.pain.type", 
                    "Number.of.vessels.fluro", "Max.HR", 
                    "Exercise.angina", "Heart.Disease")]

data.allTransformed <- data
data.allTransformed$Max.HR <- log10(data.allTransformed$Max.HR)
data.allTransformed$BP <- log10(data.allTransformed$BP)

data.simple <- data[c("Age", "Sex", "Cholesterol", "BP", "Heart.Disease")]
```

There are now clean data sets. We are going to save these in a CSV file
so that we can use it in Weka.

```{r}
write.csv(data, "01-Clean_dataset.csv", row.names = F)
write.csv(data.top5, "02-top5_p_values.csv", row.names = F)
write.csv(data.allTransformed, "03-Numeric_transformed.csv", row.names = F)
write.csv(data.simple, "04-Simple.csv", row.names = F)
```

\newpage

# Machine learning model

Now that the datasets are stored, the best model can be created. We
create a new Weka experiment with different algorithms and datasets.

## Algorithms and Settings

In weka there is a option to compare all datasets and concepts with eachother. This is done at the "experimenter" tab. Create a "new" experimenter and add the files that you've just created above. On the right pannel, add the algorithms that we want the run. The algorithms are described below. 

1.  ZeroR
2.  OneR
    1.  Bucket size 6
    2.  Bucket size 15
3.  J48
    1.  Minimum number of objects: 2, Backward Pruning: 0.25
    2.  Minimum number of objects: 2, Unpruned
    3.  Minimum number of objects: 15, Backward Pruning: 0.25
    4.  Minimum number of objects: 35, Backward Pruning: 0.25
    5.  Minimum number of objects 10, Backward Pruning: 0.025
4.  RandomForest - standard settings
5.  RandomTree - standard settings
6.  K-nears neighbours
    1.  KNN: 10
    2.  KNN: 35 (35 was the best result from CVParamaterSelection)
    3.  KNN: 35, Manhattan distance
7.  SMO - standard settings
8.  Logistic regression - standard settings
9.  NaieveBayes
10. ClassificationViaClustering - standard settings

After you've add all the algorithms, we can now run the experiment. This can be done at the "Run" tab. In the "Analyse" tab, you can retrieve the experiment results by pressing "Experiment". It's now possible to perform tests. These tests can be used to determine which concept scores the best or highest.

By selecting a comparison field, you can get the right information about the experiment. We will look at Percent_correct, Area_under_ROC, False_negative_rate, False_pisitive_rate and UserCPU_CPU_Time_Training. After the right comparison field is selected, press "Perform test". A table will now be displayed with the results. **"V"** means siginificantly higher and **\"\*\"** means significantly lower.

The last thing we want to test is the datasets. This can be done by pressing "swap". The columns and rows are now reversed. Tests can now be performed again. An comparison field can be selected again and another table with results will be showed after performing a test.

It is possible to save the experimenter's results. This can be done in the "setup" tab. A path and file name can be selected under the heading "Results destination". The results are saved after pressing "Run".

The next section looks at the experimenter's results with the above datasets and algorithms.

## Results analysis

```{r}
weka.results <- read.csv("WEKA_RESULTS.csv")
weka.results <- data.frame(weka.results)
```

We have to group the results because there are a lot of values. With grouping it is possible to see what values are per dataset or per concept. This way we don't have to go through the complete results and create groups/new data frames with results.

```{r}
Results <- weka.results %>%
 group_by(Key_Dataset, Key_Scheme, Key_Scheme_options) %>%
  summarise(mean = mean(Percent_correct), .groups = "keep")
```

\newpage

## Accuracy

Let's look at the clean dataset first.

```{r}
df <- data.frame(
  Label = c(
    "Label1", "Label2", "Label3", "Label4", 
    "Label5", "Label6", "Label7", "Label8", 
    "Label9", "Label10", "Label11", "Label12", 
    "Label13", "Label14", "Label15", "Label16", "Label17"),
  Gemiddelde = c(
    Results$mean[Results$Key_Scheme %like% "NaiveBayes" & Results$Key_Dataset == "01-Clean_dataset"],
    Results$mean[Results$Key_Scheme %like% "SMO" & Results$Key_Dataset == "01-Clean_dataset"],
    Results$mean[Results$Key_Scheme %like% "Logistic" & Results$Key_Dataset == "01-Clean_dataset"],
    Results$mean[Results$Key_Scheme %like% "IBk" & Results$Key_Dataset == "01-Clean_dataset" & Results$Key_Scheme_options %like% "-K 10"],
    Results$mean[Results$Key_Scheme %like% "IBk" & Results$Key_Dataset == "01-Clean_dataset" & Results$Key_Scheme_options %like% "-K 35" & Results$Key_Scheme_options %like% "EuclideanDistance"],
    Results$mean[Results$Key_Scheme %like% "IBk" & Results$Key_Dataset == "01-Clean_dataset" & Results$Key_Scheme_options %like% "ManhattanDistance"],
    Results$mean[Results$Key_Scheme %like% "ClassificationViaClustering" & Results$Key_Dataset == "01-Clean_dataset"],
    Results$mean[Results$Key_Scheme %like% "OneR" & Results$Key_Dataset == "01-Clean_dataset" & Results$Key_Scheme_options %like% "-B 15"],
    Results$mean[Results$Key_Scheme %like% "OneR" & Results$Key_Dataset == "01-Clean_dataset" & Results$Key_Scheme_options %like% "-B 6"],
    Results$mean[Results$Key_Scheme %like% "ZeroR" & Results$Key_Dataset == "01-Clean_dataset"],
    Results$mean[Results$Key_Scheme %like% "J48" & Results$Key_Dataset == "01-Clean_dataset" & Results$Key_Scheme_options %like% "-C 0.025 -M 10"],
    Results$mean[Results$Key_Scheme %like% "J48" & Results$Key_Dataset == "01-Clean_dataset" & Results$Key_Scheme_options %like% "-C 0.25 -M 15"],
    Results$mean[Results$Key_Scheme %like% "J48" & Results$Key_Dataset == "01-Clean_dataset" & Results$Key_Scheme_options %like% "-C 0.25 -M 2"],
    Results$mean[Results$Key_Scheme %like% "J48" & Results$Key_Dataset == "01-Clean_dataset" & Results$Key_Scheme_options %like% "-C 0.25 -M 35"],
    Results$mean[Results$Key_Scheme %like% "J48" & Results$Key_Dataset == "01-Clean_dataset" & Results$Key_Scheme_options %like% "-U -M 2"],
    Results$mean[Results$Key_Scheme %like% "RandomForest" & Results$Key_Dataset == "01-Clean_dataset"],
    Results$mean[Results$Key_Scheme %like% "RandomTree" & Results$Key_Dataset == "01-Clean_dataset"])
  )

ggplot(df, aes(x = Label, y = Gemiddelde, fill = Label)) +
  geom_bar(stat = "identity") +
  labs(title = "Mean ACC per Algorithm in clean dataset", 
       x = "Algorithm", y = "Mean") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        legend.key.size = unit(0.4, "cm")) + coord_cartesian(ylim=c(50,100))
```

Naive bayes scores highest accuracy. This accuracy is for the clean dataset. For the other three datasets, NaiveBayes has the highest ACC as well.


We will now look at all the four datasets at once.

```{r}
Results.4.datasets <- weka.results %>%
 group_by(Key_Scheme, Key_Scheme_options) %>%
  summarise(mean = mean(Percent_correct), .groups = "keep")

pander(head(Results[c(2, 4)]))
```

We can conclude that:

- NaiveBayes scores the highest
- Logistic regression scores seccond highest

If we only look at our clean dataset, we have the same results.

```{r}
Results <- weka.results %>%
 group_by(Key_Dataset[1], Key_Scheme, Key_Scheme_options) %>%
  summarise(mean = mean(Percent_correct), .groups = "keep")

pander(head(Results[c(2, 4)]))
```
 
It's the same result as the four datasets combined, so Naieve bayes and logistic are the best here.

Let's look at other comparison fields.

\newpage

## Area under ROC

The table below pulls out the "simple" concepts. This is because otherwise a large table will be created with values that are not relevant. above, the ACC is visible for all algorithms.

| Dataset                |  (16) Bayes  | (5)    | (6)    | (7)    | (8)    | (10) | (12) | (13)   | (14) | (15)   | 
| -----------------------|--------------|--------|--------|--------|--------|------|------|--------|------|--------|
| 01-Clean_dataset       | (100)   0.91 | 0.78 * | 0.74 * | 0.76 * | 0.89   | 0.89 | 0.90 | 0.83 * | 0.90 | 0.78 * |
| 02-top5_p_values       | (100)   0.90 | 0.78 * | 0.74 * | 0.79 * | 0.84 * | 0.88 | 0.89 | 0.83 * | 0.90 | 0.80 * |
| 03-Numeric_transformed | (100)   0.91 | 0.78 * | 0.74 * | 0.76 * | 0.89   | 0.90 | 0.90 | 0.83 * | 0.90 | 0.78 * |
| 04-Simple              | (100)   0.72 | 0.68   | 0.68   | 0.66 * | 0.71   | 0.71 | 0.74 | 0.63 * | 0.72 | 0.64 * |

Key:

(5) trees.J48 '-U -M 2' -217733168393644444
(6) trees.J48 '-C 0.25 -M 15' -217733168393644444
(7) trees.J48 '-C 0.25 -M 35' -217733168393644444
(8) trees.J48 '-C 0.025 -M 10' -217733168393644444
(10) trees.RandomTree '-K 0 -M 1.0 -V 0.001 -S 1' -9051119597407396024
(12) lazy.IBk '-K 35 -W 0 -A \"weka.core.neighboursearch.LinearNNSearch -A \\\"weka.core.EuclideanDistance -R first-last\\\"\"' -3080186098777067172
(13) lazy.IBk '-K 35 -W 0 -A \"weka.core.neighboursearch.LinearNNSearch -A \\\"weka.core.ManhattanDistance -R first-last\\\"\"' -3080186098777067172
(14) functions.SMO '-C 1.0 -L 0.001 -P 1.0E-12 -N 0 -V -1 -W 1 -K \"functions.supportVector.PolyKernel -E 1.0 -C 250007\" -calibrator \"functions.Logistic -R 1.0E-8 -M -1 -num-decimal-places 4\"' -6585883636378691736
(15) functions.Logistic '-R 1.0E-8 -M -1 -num-decimal-places 4' 3932117032546553727
(16) bayes.NaiveBayes '' 5995231201785697655

RandomTree, K-nearest neighbours (KNN 35, euclideanDistance) and NaieveBayes are the highest here. There are very close to eachother, but NaiveBayes is at top followed by K-nearest neighbours.

## False negative rate and False positive rate

We want a concept with a low false negative rate and a low false positive rate. 

For the false negative rate SMO and ClassificationViaCLustering score lower over 4 datasets. K-nearest neighbours scores low as well. Again, NaiveBayes scores here low too. It is difficult to make conclusions with this because there are all differences between data sets.

For the flase positive rate only zeroR scores lower. But that makes sense. Not looking at ZeroR, K-nearest neighbours and NaiveBayes scores the lowest. 

## UserCPU_CPU_Time_Training.

The UserCPU_CPU_Time_Training for each model is very fast. ZeroR scores the fastest here. But this model will not not be used eventually.

## Dataset comparison

Now all that remains is to look for the best dataset. For now, we will only look at the ACC, because attribute selection will be looked at next.

```{r}
Results <- weka.results %>%
 group_by(Key_Dataset) %>%
  summarise(mean = mean(Percent_correct), .groups = "keep")

pander(head(Results))
```

| Dataset                   | (1) 01-Clean_da  | (2) 02-top5_ | (3) 03-Numer. | (4) 04-Simpl |
|---------------------------|------------------|--------------|---------------|--------------|
| rules.ZeroR '' 4805554146 | (100)   55.55556 |   55.55556   |  55.55556     | 55.55556     |
| rules.OneR '-B 6' -345942 | (100)   71.62963 |   73.07407   |  71.62963     | 51.40741 *   |
| rules.OneR '-B 15' -34594 | (200)   71.62963 |   73.07407   |  71.62963     | 60.81481 *   |
| trees.J48 '-C 0.25 -M 2'  | (100)   76.40741 |   80.96296 v |  76.44444     | 65.44444 *   |
| trees.J48 '-U -M 2' -2177 | (100)   75.81481 |   81.07407 v |  75.92593     | 65.22222 *   |
| trees.J48 '-C 0.25 -M 15' | (100)   73.81481 |   73.00000   |  73.81481     | 63.07407 *   |
| trees.J48 '-C 0.25 -M 35' | (100)   72.44444 |   73.00000   |  72.44444     | 64.62963 *   |
| trees.J48 '-C 0.025 -M 10 | (100)   73.88889 |   76.51852   |  73.88889     | 63.22222 *   |
| trees.RandomForest '-P 10 | (100)   81.33333 |   79.33333   |  82.22222     | 64.96296 *   |
| trees.RandomTree '-K 0 -M | (100)   73.00000 |   74.59259   |  73.88889     | 62.48148 *   |
| lazy.IBk '-K 10 -W 0 -A   | (100)   80.85185 |   80.88889   |  80.92593     | 64.22222 *   |
| lazy.IBk '-K 35 -W 0 -A   | (100)   83.66667 |   83.37037   |  83.29630     | 67.25926 *   |
| lazy.IBk '-K 35 -W 0 -A   | (100)   83.44444 |   83.18519   |  83.40741     | 67.03704 *   |
| functions.SMO '-C 1.0 -L  | (100)   84.07407 |   83.70370   |  84.03704     | 62.66667 *   |
| functions.Logistic '-R 1. | (100)   83.96296 |   83.81481   |  83.85185     | 66.03704 *   |
| bayes.NaiveBayes '' 59952 | (100)   84.88889 |   83.44444   |  84.14815     | 68.25926 *   |
| meta.ClassificationViaClu | (100)   78.07407 |   80.81481   |  78.14815     | 62.11111 *   |

By looking at these two tables, we can see that the dataset with the lowest p-values scores better than the "clean" dataset. A model bases on only the best 5 attributes scores better than a model with all models. The five attributes are determined with 'simple' t-tests. This can be calculated much better in Weka. This will examined in the next section. Specific algorithms and search methods will then be used to determine the best attributes.

## Attribute Selection

In weka it is possible to look which attributes in your datasets are suited best for your model. This can be done on multiple ways...

\newpage

```{=tex}
\begin{thebibliography}{3}

\bibitem{dataset}
(2023, 12 januari).: \textit{Predicting heart disease using clinical variables}. <https://www.kaggle.com/datasets/thedevastator/predicting-heart-disease-risk-using-clinical-var>

\bibitem{angina_chol}
Harvard Health. (2021, 21 september).: \textit{Angina: Symptoms, diagnosis and Treatments}. 
<https://www.health.harvard.edu/heart-health/angina-symptoms-diagnosis-and-treatments>

\bibitem{maxHR}
Perret‐Guillaume, C., Joly, L. Bénétos, A. (2009).: \textit{Heart rate as a risk factor for cardiovascular disease. Progress in Cardiovascular Diseases, 52(1), 6–10}

\end{thebibliography}
```

Attribute selection checklist


1. Ranking
2. Wrapper
3. CSF





